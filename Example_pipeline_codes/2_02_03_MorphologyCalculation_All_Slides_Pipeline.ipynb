{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02e4f55d-65bd-41cf-8de1-d445ba455667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /data/Lab_ruppin/Ranjan/HnE/\n",
      "Nuclear morphology features saved for slide TCGA-3C-AALI-01Z-00-DX1_2513_tiles to TCGA_BRCA_FFPE/outputs/HoverNet/TCGA-3C-AALI-01Z-00-DX1_2513_tiles/features/TCGA-3C-AALI-01Z-00-DX1_2513_tiles.csv\n",
      "Nuclear morphology features saved for slide TCGA-3C-AALI-01Z-00-DX2_3951_tiles to TCGA_BRCA_FFPE/outputs/HoverNet/TCGA-3C-AALI-01Z-00-DX2_3951_tiles/features/TCGA-3C-AALI-01Z-00-DX2_3951_tiles.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Read JSON data\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 63\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Filter nuclei labeled as tumor (type=1)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m nuclei \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnuc\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.10/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/usr/local/Anaconda/envs/py3.10/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### ------------------------------------------------------------------------------------------\n",
    "#### author: Ranjan Barman, date: Aug 22, 2025\n",
    "#### Compute molecular features (tumor/cancer only) from Hover-Net predicted json files (all slides)\n",
    "#### --------------------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# Set working directory\n",
    "_wpath_ = \"/data/Lab_ruppin/Ranjan/HnE/\"\n",
    "os.makedirs(_wpath_, exist_ok=True)\n",
    "os.chdir(_wpath_)\n",
    "\n",
    "print(\"Working directory:\", _wpath_)\n",
    "\n",
    "# Dataset name\n",
    "dataset_name = \"TCGA_BRCA_FFPE\"\n",
    "\n",
    "# Parse args\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-slide\", type=str, required=True, help=\"Slide folder name to process\")\n",
    "# NEW: where Hover-Net outputs live (jsons under <hovernet_root>/<slide>/masks/json)\n",
    "parser.add_argument(\n",
    "    \"--hovernet_root\",\n",
    "    type=str,\n",
    "    default=os.path.join(_wpath_, dataset_name, \"outputs\", \"HoverNet\") + \"/\",\n",
    "    help=\"Root directory containing <slide>/masks/json from HoVer-Net\"\n",
    ")\n",
    "# NEW: where to save morphology results (Morph/<slide>/tumor_nuclei.csv)\n",
    "parser.add_argument(\n",
    "    \"--out_dir\",\n",
    "    type=str,\n",
    "    default=os.path.join(_wpath_, dataset_name, \"outputs\", \"Morph\") + \"/\",\n",
    "    help=\"Base directory to write morphology CSVs (per slide subfolder)\"\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\n",
    "slide_folder = args.slide\n",
    "\n",
    "# Base dirs (NOW come from args)\n",
    "hovernet_base_dir = args.hovernet_root  # CHANGED\n",
    "slide_path = os.path.join(hovernet_base_dir, slide_folder)\n",
    "\n",
    "if not os.path.isdir(slide_path):\n",
    "    print(f\"Error: {slide_folder} is not a valid directory under {hovernet_base_dir}\")\n",
    "    exit(1)\n",
    "\n",
    "tiles_dir    = os.path.join(slide_path, \"tiles\")\n",
    "json_dir     = os.path.join(slide_path, \"masks\", \"json\")\n",
    "overlay_dir  = os.path.join(slide_path, \"masks\", \"overlay\")\n",
    "\n",
    "# Output dir/file (write directly to Morph/<slide>/tumor_nuclei.csv)\n",
    "features_dir = os.path.join(args.out_dir, slide_folder)  # CHANGED\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "output_file  = os.path.join(features_dir, \"tumor_nuclei.csv\")  # CHANGED\n",
    "\n",
    "# List all JSON files\n",
    "if not os.path.exists(json_dir):\n",
    "    print(f\"Skipping {slide_folder}: No JSON directory found at {json_dir}.\")\n",
    "    exit(1)\n",
    "\n",
    "json_files = sorted(\n",
    "    [f for f in os.listdir(json_dir) if f.endswith(\".json\")],\n",
    "    key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])\n",
    ")\n",
    "\n",
    "# Process each tile\n",
    "results = []\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(json_dir, json_file)\n",
    "    tile_name = json_file.replace(\".json\", \"\")\n",
    "\n",
    "    # Read JSON data\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Filter nuclei labeled as tumor (type=1)\n",
    "    nuclei = data.get('nuc', {})\n",
    "    tumor_nuclei = {key: val for key, val in nuclei.items() if val.get('type') == 1}\n",
    "\n",
    "    if tumor_nuclei:\n",
    "        for key, nucleus in tumor_nuclei.items():\n",
    "            nucleus_id = key\n",
    "\n",
    "            # Ensure proper numpy formats\n",
    "            contour_pts = np.asarray(nucleus['contour'], dtype=np.float32)  # Nx2\n",
    "            polygon = Polygon(contour_pts)\n",
    "            area = polygon.area\n",
    "            perimeter = polygon.length\n",
    "\n",
    "            # Fit ellipse (cv2 needs shape Nx1x2)\n",
    "            if contour_pts.shape[0] >= 5:\n",
    "                ellipse = cv2.fitEllipse(contour_pts.reshape(-1, 1, 2))\n",
    "                major_axis = float(max(ellipse[1]))\n",
    "                minor_axis = float(min(ellipse[1]))\n",
    "            else:\n",
    "                major_axis = minor_axis = 0.0\n",
    "\n",
    "            # Eccentricity\n",
    "            if major_axis > 0:\n",
    "                eccentricity = float(np.sqrt(1.0 - (minor_axis ** 2) / (major_axis ** 2)))\n",
    "            else:\n",
    "                eccentricity = 0.0\n",
    "\n",
    "            # Circularity\n",
    "            if perimeter > 0:\n",
    "                circularity = float((4.0 * np.pi * area) / (perimeter ** 2))\n",
    "            else:\n",
    "                circularity = 0.0\n",
    "\n",
    "            results.append([\n",
    "                slide_folder, tile_name, nucleus_id,\n",
    "                area, major_axis, minor_axis, perimeter, eccentricity, circularity\n",
    "            ])\n",
    "\n",
    "# To DataFrame & save\n",
    "columns = [\"Slide\", \"Tile\", \"Nucleus ID\", \"Area\", \"Major Axis\", \"Minor Axis\", \"Perimeter\", \"Eccentricity\", \"Circularity\"]\n",
    "df_results = pd.DataFrame(results, columns=columns)\n",
    "df_results.to_csv(output_file, mode='w', index=False, header=True)\n",
    "\n",
    "print(f\"Nuclear morphology features saved for slide {slide_folder} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb140e2-58f2-4b5a-81db-7d6441ff2dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
